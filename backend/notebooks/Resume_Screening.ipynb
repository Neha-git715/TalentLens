{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # safe backend\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "      <th>cleaned_resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category                                             Resume  \\\n",
       "0  Data Science  Skills * Programming Languages: Python (pandas...   \n",
       "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...   \n",
       "2  Data Science  Areas of Interest Deep Learning, Control Syste...   \n",
       "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...   \n",
       "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...   \n",
       "\n",
       "  cleaned_resume  \n",
       "0                 \n",
       "1                 \n",
       "2                 \n",
       "3                 \n",
       "4                 "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumeDataSet = pd.read_csv('../data/resume_dataset.csv', encoding='utf-8')\n",
    "resumeDataSet['cleaned_resume'] = ''\n",
    "resumeDataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the distinct categories of resume -\n",
      "['Data Science' 'HR' 'Advocate' 'Arts' 'Web Designing'\n",
      " 'Mechanical Engineer' 'Sales' 'Health and fitness' 'Civil Engineer'\n",
      " 'Java Developer' 'Business Analyst' 'SAP Developer' 'Automation Testing'\n",
      " 'Electrical Engineering' 'Operations Manager' 'Python Developer'\n",
      " 'DevOps Engineer' 'Network Security Engineer' 'PMO' 'Database' 'Hadoop'\n",
      " 'ETL Developer' 'DotNet Developer' 'Blockchain' 'Testing']\n"
     ]
    }
   ],
   "source": [
    "print (\"Displaying the distinct categories of resume -\")\n",
    "print (resumeDataSet['Category'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the distinct categories of resume and the number of records belonging to each category -\n",
      "Category\n",
      "Java Developer               14\n",
      "Database                     11\n",
      "HR                           11\n",
      "Data Science                 10\n",
      "Advocate                     10\n",
      "Automation Testing            7\n",
      "DevOps Engineer               7\n",
      "Testing                       7\n",
      "DotNet Developer              7\n",
      "Hadoop                        7\n",
      "SAP Developer                 6\n",
      "Python Developer              6\n",
      "Health and fitness            6\n",
      "Civil Engineer                6\n",
      "Arts                          6\n",
      "Business Analyst              6\n",
      "Web Designing                 5\n",
      "Mechanical Engineer           5\n",
      "Sales                         5\n",
      "ETL Developer                 5\n",
      "Electrical Engineering        5\n",
      "Blockchain                    5\n",
      "Network Security Engineer     5\n",
      "Operations Manager            4\n",
      "PMO                           3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (\"Displaying the distinct categories of resume and the number of records belonging to each category -\")\n",
    "print (resumeDataSet['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='count', ylabel='Category'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(y=\"Category\", data=resumeDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetCounts = resumeDataSet['Category'].value_counts()\n",
    "targetLabels  = resumeDataSet['Category'].unique()\n",
    "# Make square figures and axes\n",
    "plt.figure(1, figsize=(25,25))\n",
    "the_grid = GridSpec(2, 2)\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap('coolwarm')\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, 6)]\n",
    "plt.subplot(the_grid[0, 1], aspect=1, title='CATEGORY DISTRIBUTION')\n",
    "\n",
    "source_pie = plt.pie(targetCounts, labels=targetLabels, autopct='%1.1f%%', shadow=True, colors=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanResume(resumeText):\n",
    "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
    "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
    "    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
    "    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
    "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
    "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n",
    "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
    "    return resumeText\n",
    "    \n",
    "resumeDataSet['cleaned_resume'] = resumeDataSet.Resume.apply(lambda x: cleanResume(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Exprience', 601), ('months', 499), ('company', 496), ('Details', 490), ('description', 436), ('1', 345), ('Project', 288), ('data', 243), ('project', 234), ('year', 218), ('SQL', 212), ('6', 209), ('Maharashtra', 205), ('team', 203), ('Less', 203), ('using', 195), ('January', 173), ('Management', 160), ('Pune', 147), ('C', 142), ('Education', 136), ('Ltd', 136), ('management', 135), ('database', 132), ('Data', 125), ('monthsCompany', 121), ('Engineering', 121), ('Server', 121), ('Database', 117), ('India', 117), ('like', 117), ('The', 116), ('various', 115), ('Pvt', 115), ('business', 114), ('application', 114), ('Responsibilities', 113), ('development', 112), ('System', 110), ('reports', 109), ('2', 109), ('A', 108), ('Java', 106), ('issues', 104), ('requirements', 104), ('Mumbai', 101), ('work', 98), ('system', 96), ('Role', 96), ('Test', 96)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "oneSetOfStopWords = set(stopwords.words('english')+['``',\"''\"])\n",
    "totalWords =[]\n",
    "Sentences = resumeDataSet['Resume'].values\n",
    "cleanedSentences = \"\"\n",
    "for i in range(0,160):\n",
    "    cleanedText = cleanResume(Sentences[i])\n",
    "    cleanedSentences += cleanedText\n",
    "    requiredWords = nltk.word_tokenize(cleanedText)\n",
    "    for word in requiredWords:\n",
    "        if word not in oneSetOfStopWords and word not in string.punctuation:\n",
    "            totalWords.append(word)\n",
    "    \n",
    "wordfreqdist = nltk.FreqDist(totalWords)\n",
    "mostcommon = wordfreqdist.most_common(50)\n",
    "print(mostcommon)\n",
    "\n",
    "wc = WordCloud().generate(cleanedSentences)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "var_mod = ['Category']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    resumeDataSet[i] = le.fit_transform(resumeDataSet[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature completed .....\n",
      "(135, 1500)\n",
      "(34, 1500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "requiredText = resumeDataSet['cleaned_resume'].values\n",
    "requiredTarget = resumeDataSet['Category'].values\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    stop_words='english',\n",
    "    max_features=1500)\n",
    "word_vectorizer.fit(requiredText)\n",
    "WordFeatures = word_vectorizer.transform(requiredText)\n",
    "\n",
    "print (\"Feature completed .....\")\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(WordFeatures,requiredTarget,random_state=0, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNeighbors Classifier on training set: 0.84\n",
      "Accuracy of KNeighbors Classifier on test set: 0.82\n",
      "\n",
      " Classification report for classifier OneVsRestClassifier(estimator=KNeighborsClassifier()):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.50      1.00      0.67         2\n",
      "           3       1.00      1.00      1.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       0.50      1.00      0.67         1\n",
      "           9       0.80      1.00      0.89         4\n",
      "          11       1.00      0.67      0.80         3\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         3\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         1\n",
      "          17       1.00      0.50      0.67         2\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       1.00      0.67      0.80         3\n",
      "          21       1.00      1.00      1.00         1\n",
      "          22       1.00      1.00      1.00         1\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.82        34\n",
      "   macro avg       0.74      0.74      0.72        34\n",
      "weighted avg       0.84      0.82      0.81        34\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(KNeighborsClassifier())\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "print('Accuracy of KNeighbors Classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of KNeighbors Classifier on test set: {:.2f}'.format(clf.score(X_test, y_test)))\n",
    "\n",
    "print(\"\\n Classification report for classifier %s:\\n%s\\n\" % (clf, metrics.classification_report(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
